{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG1rsM-Vo0Fa"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY3uGzUuEnei"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGxnjUsdrk-j"
      },
      "source": [
        "## Download IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMb01VMwo6p5"
      },
      "source": [
        "dataset, info = tfds.load('imdb_reviews', split='train', with_info=True)\n",
        "df = tfds.as_dataframe(dataset.take(-1), info)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAM0XIvSsL2d"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-WgVOLysTUk"
      },
      "source": [
        "VOCAB_SIZE = 5000  # model can learn VOCAB_SIZE (vocabulary size) number of words\n",
        "SEQ_LEN = 100  # model can take a maximum of SEQ_LEN (sequence length) number of words in a single sentence\n",
        "EMB_DIM = 50  # Number of dimensions to map the words to vectors\n",
        "EPOCHS = 10  # number of epochs for the model to train\n",
        "BATCH_SIZE = 32  # number of samples to process at once"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHKpTanruFc3"
      },
      "source": [
        "## Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z7DyynquHCZ"
      },
      "source": [
        "labels = df['label'].values\n",
        "reviews = [str(text) for text in df['text']]\n",
        "\n",
        "tk = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tk.fit_on_texts(reviews)  # map words to numbers\n",
        "\n",
        "sequences = tk.texts_to_sequences(reviews)  # convert words to numbers\n",
        "x = pad_sequences(sequences, maxlen=SEQ_LEN, padding='post')  # pad samples to have equal length of SEQ_LEN\n",
        "y = labels.reshape(-1, 1)  # reshape from 1D array to 2D array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nO6FvZatbFB"
      },
      "source": [
        "## Split train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Mk0MV7tfkS"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhhMQqfUyTBv"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwPUfY6dH8Ma"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(VOCAB_SIZE, EMB_DIM, input_length=SEQ_LEN))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3fSGxcEyVPd"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNXgGSr9yWBA"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yOEMgXfyXLN"
      },
      "source": [
        "## Preprocess test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pxrzMS_yZhR"
      },
      "source": [
        "test_dataset, info = tfds.load('imdb_reviews', split='test', with_info=True)\n",
        "test_df = tfds.as_dataframe(test_dataset.take(-1), info)\n",
        "\n",
        "test_labels = test_df['label'].values\n",
        "test_reviews = [str(text) for text in test_df['text']]\n",
        "\n",
        "test_sequences = tk.texts_to_sequences(test_reviews)  # convert words to numbers\n",
        "x_test = pad_sequences(test_sequences, maxlen=SEQ_LEN, padding='post')  # pad samples to have equal length of SEQ_LEN\n",
        "y_test = test_labels.reshape(-1, 1)  # reshape from 1D array to 2D array\n",
        "\n",
        "x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpoYi04vz5wN"
      },
      "source": [
        "## Evaluate model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yrtxl3Iz8hk"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss: {} | Test Accuracy: {}%\".format(loss, accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58PFR3qFyaKi"
      },
      "source": [
        "## Predict on custom text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYXfqoCKycQq"
      },
      "source": [
        "while True:\n",
        "    user_text = input(\"\\nEnter your text here; q to quit : \")\n",
        "    if user_text == 'q':\n",
        "        break\n",
        "\n",
        "    user_sequence = tk.texts_to_sequences([user_text])\n",
        "    user_sequence = pad_sequences(user_sequence, maxlen=SEQ_LEN, padding='post')\n",
        "\n",
        "    prediction = model.predict(user_sequence)[0][0]\n",
        "\n",
        "    if prediction >= 0.5:\n",
        "        sentiment = 'POSITIVE'\n",
        "    else:\n",
        "        sentiment = 'NEGATIVE'\n",
        "\n",
        "    print('Sentiment: {} | Score: {}'.format(sentiment, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}